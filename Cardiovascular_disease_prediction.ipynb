{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cardiovascular Diesase Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset source : https://www.kaggle.com/datasets/sulianova/cardiovascular-disease-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from numpy import mean\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 13)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"E:/cardio_disease.csv\", sep=';')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    35021\n",
       "1    34979\n",
       "Name: cardio, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting Number of distribution.\n",
    "dictribution = data[\"cardio\"].value_counts()\n",
    "dictribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Dataset:  70000\n",
      "Number of Attributes:  13\n"
     ]
    }
   ],
   "source": [
    "# Checking Shape of the dataset.\n",
    "print('Length of Dataset: ', data.shape[0])\n",
    "print('Number of Attributes: ', data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "age            0\n",
       "gender         0\n",
       "height         0\n",
       "weight         0\n",
       "ap_hi          0\n",
       "ap_lo          0\n",
       "cholesterol    0\n",
       "gluc           0\n",
       "smoke          0\n",
       "alco           0\n",
       "active         0\n",
       "cardio         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Null values in all features.\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               int64\n",
       "age              int64\n",
       "gender           int64\n",
       "height           int64\n",
       "weight         float64\n",
       "ap_hi            int64\n",
       "ap_lo            int64\n",
       "cholesterol      int64\n",
       "gluc             int64\n",
       "smoke            int64\n",
       "alco             int64\n",
       "active           int64\n",
       "cardio           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Data Types of every column.\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Unnecessary Column.\n",
    "data.drop('id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data into Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, data.columns != 'cardio']     # All columns except target variable.\n",
    "y = data[['cardio']]                          # Target Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52500, 11)\n",
      "(52500, 1)\n",
      "(17500, 11)\n",
      "(17500, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Modelling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(learning_rate=0.01, max_depth=5, n_estimators=400)\n",
    "gb.fit(X_train,y_train.values.ravel())\n",
    "y_pred = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[6866 1894]\n",
      " [2768 5972]]\n",
      "------------------------------------\n",
      "AUC Score: 0.7335425744229543\n",
      "------------------------------------\n",
      "Accuracy of Random Forest: 73.36 %\n",
      "------------------------------------\n",
      "Recall: 0.6832951945080091\n",
      "------------------------------------\n",
      "Precision: 0.7592168827866769\n",
      "------------------------------------\n",
      "Specificity: 0.7837899543378996\n",
      "------------------------------------\n",
      "Sensitivity: 0.6832951945080091\n",
      "------------------------------------\n",
      "Miss Rate (False Positive Rate): 0.21621004566210045\n",
      "------------------------------------\n",
      "Miss Rate (False Negative Rate): 0.31670480549199087\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.78      0.75      8760\n",
      "           1       0.76      0.68      0.72      8740\n",
      "\n",
      "    accuracy                           0.73     17500\n",
      "   macro avg       0.74      0.73      0.73     17500\n",
      "weighted avg       0.74      0.73      0.73     17500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print('------------------------------------')\n",
    "\n",
    "AUC_Score = roc_auc_score(y_test,y_pred)\n",
    "print(\"AUC Score:\",AUC_Score)\n",
    "print('------------------------------------')\n",
    "\n",
    "\n",
    "accuracy = gb.score(X_test, y_test)\n",
    "print(\"Accuracy of Random Forest:\",accuracy*100,\"%\")\n",
    "print('------------------------------------')\n",
    "\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(y_test,y_pred)\n",
    "print(\"Recall:\",recall)\n",
    "print('------------------------------------')\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred)\n",
    "print(\"Precision:\",precision)\n",
    "print('------------------------------------')\n",
    "\n",
    "specificity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "print(\"Specificity:\", specificity)\n",
    "print('------------------------------------')\n",
    "\n",
    "sensitivity = cm[1,1]/(cm[1,1]+cm[1,0])\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "print('------------------------------------')\n",
    "miss_rate = cm[0,1]/(cm[0,1]+cm[0,0])\n",
    "print(\"Miss Rate (False Positive Rate):\", miss_rate)\n",
    "\n",
    "print('------------------------------------')\n",
    "miss_rate_FNR = cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "print(\"Miss Rate (False Negative Rate):\", miss_rate_FNR)\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = GaussianNB()\n",
    "NB.fit(X_train,y_train.values.ravel())\n",
    "y_pred = NB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[6126 2634]\n",
      " [2921 5819]]\n",
      "------------------------------------\n",
      "AUC Score: 0.6825522710886806\n",
      "------------------------------------\n",
      "Accuracy of Naive Bayes: 58.502857142857145 %\n",
      "------------------------------------\n",
      "Recall: 0.6657894736842105\n",
      "------------------------------------\n",
      "Precision: 0.6883946527859931\n",
      "------------------------------------\n",
      "Specificity: 0.6993150684931507\n",
      "------------------------------------\n",
      "Sensitivity: 0.6657894736842105\n",
      "------------------------------------\n",
      "Miss Rate (False Positive Rate): 0.30068493150684933\n",
      "------------------------------------\n",
      "Miss Rate (False Negative Rate): 0.33421052631578946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.70      0.69      8760\n",
      "           1       0.69      0.67      0.68      8740\n",
      "\n",
      "    accuracy                           0.68     17500\n",
      "   macro avg       0.68      0.68      0.68     17500\n",
      "weighted avg       0.68      0.68      0.68     17500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print('------------------------------------')\n",
    "\n",
    "AUC_Score = roc_auc_score(y_test,y_pred)\n",
    "print(\"AUC Score:\",AUC_Score)\n",
    "print('------------------------------------')\n",
    "\n",
    "\n",
    "accuracy = NB.score(X_test, y_test)\n",
    "print(\"Accuracy of Naive Bayes:\",accuracy*100,\"%\")\n",
    "print('------------------------------------')\n",
    "\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(y_test,y_pred)\n",
    "print(\"Recall:\",recall)\n",
    "print('------------------------------------')\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred)\n",
    "print(\"Precision:\",precision)\n",
    "print('------------------------------------')\n",
    "\n",
    "specificity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "print(\"Specificity:\", specificity)\n",
    "print('------------------------------------')\n",
    "\n",
    "sensitivity = cm[1,1]/(cm[1,1]+cm[1,0])\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "print('------------------------------------')\n",
    "miss_rate = cm[0,1]/(cm[0,1]+cm[0,0])\n",
    "print(\"Miss Rate (False Positive Rate):\", miss_rate)\n",
    "\n",
    "print('------------------------------------')\n",
    "miss_rate_FNR = cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "print(\"Miss Rate (False Negative Rate):\", miss_rate_FNR)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K- Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: .values.ravel( ) is used to eliminate dataconversion warning.\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train,y_train.values.ravel())\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[6126 2634]\n",
      " [2921 5819]]\n",
      "------------------------------------\n",
      "AUC Score: 0.6825522710886806\n",
      "------------------------------------\n",
      "Accuracy of KNN Classifier: 68.25714285714287 %\n",
      "------------------------------------\n",
      "Recall: 0.6657894736842105\n",
      "------------------------------------\n",
      "Precision: 0.6883946527859931\n",
      "------------------------------------\n",
      "Specificity: 0.6993150684931507\n",
      "------------------------------------\n",
      "Sensitivity: 0.6657894736842105\n",
      "------------------------------------\n",
      "Miss Rate (False Positive Rate): 0.30068493150684933\n",
      "------------------------------------\n",
      "Miss Rate (False Negative Rate): 0.33421052631578946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.70      0.69      8760\n",
      "           1       0.69      0.67      0.68      8740\n",
      "\n",
      "    accuracy                           0.68     17500\n",
      "   macro avg       0.68      0.68      0.68     17500\n",
      "weighted avg       0.68      0.68      0.68     17500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print('------------------------------------')\n",
    "\n",
    "AUC_Score = roc_auc_score(y_test,y_pred)\n",
    "print(\"AUC Score:\",AUC_Score)\n",
    "print('------------------------------------')\n",
    "\n",
    "\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "print(\"Accuracy of KNN Classifier:\",accuracy*100,\"%\")\n",
    "print('------------------------------------')\n",
    "\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(y_test,y_pred)\n",
    "print(\"Recall:\",recall)\n",
    "print('------------------------------------')\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred)\n",
    "print(\"Precision:\",precision)\n",
    "print('------------------------------------')\n",
    "\n",
    "specificity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "print(\"Specificity:\", specificity)\n",
    "print('------------------------------------')\n",
    "\n",
    "sensitivity = cm[1,1]/(cm[1,1]+cm[1,0])\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "print('------------------------------------')\n",
    "miss_rate = cm[0,1]/(cm[0,1]+cm[0,0])\n",
    "print(\"Miss Rate (False Positive Rate):\", miss_rate)\n",
    "\n",
    "print('------------------------------------')\n",
    "miss_rate_FNR = cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "print(\"Miss Rate (False Negative Rate):\", miss_rate_FNR)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95f57ecaf1e4684a97728584cbdcdcfb0a14de4fde6afb1e55592db96a99a5c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
